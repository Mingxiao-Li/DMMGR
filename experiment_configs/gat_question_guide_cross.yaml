ENV:
  gpus: "'2'"
EXECUTION:
  name: GExecution
  resume: False
  loaded_checkpoint_path: None 
  log_path: train_info_folder/train_info_{version}.txt
  version: question_guid_cross_att
  save_path: checkpoints/checkpoints_{version}/
  output_steps: 10
  ren_mode: train

MODEL:
  name: GATQuestionGuidedCross
  parent_path: /cw/liir/NoCsBack/testliir/datasets/
  word2index_path: KR_VQR/word2index.json
  pretrained_word_path: KR_VQR/glove.42B.300d/glove.42B.300d.txt
  candidate_answer_emb_path: KR_VQR/candidate_answer_emb.pt
  # model parameters
  vocab_size: 12941
  embeded_size: 300
  max_img_node_len: 2 # 10 for using sg, 2 for using predicted symbolic
  max_img_edge_len: 5 # 10 for using sg, 5 for using predicted symbolic
  max_kg_len: 10
  use_glove_emb: True 
  num_layers: 2
  fine_tune: False 
  dropout: 0.1 
  use_scene_graph: False
  img_edge_dim: 5
  hidden_size: 1024
  act_fn: RELU

  LanguageEncoder:
    rnn_type: lstm 
    input_size: 300
    hidden_size: 512
    num_layers: 1
    bidirectional: True 
    dropout: 0.1
    output_last_layer: True 
  
  GatQgcLayer:
    in_dims: 512
    rel_dims: 512
    out_dims:  512 
    QuestionGuideAttImg:
      dropout: 0.1
      ques_dim: 1024
      node_att_prj_dim: 512
      node_dim: 512
      edge_att_prj_dim: 512 
      edge_dim: 512
    QuestionGuideAttKg:
      dropout: 0.1
      ques_dim: 1024
      node_att_prj_dim: 512
      node_dim: 512
      edge_att_prj_dim: 512 
      edge_dim: 512 
    CrossGraphAtt:
      dropout: 0.1
      ques_dim: 1024
      img_node_dim: 512
      kg_node_dim: 512
      hidden_size: 512
      num_heads: 8
      hidden_size_head: 64
      mid_size: 512
  
  PredictionHead:
    dropout: 0.1
    hidden_size: 512
    mid_size: 2048
    num_answers: 6900

OPTIM:
  lr_base: 0.0001
  lr_scheduler: warmup
  grad_accu_step: 1
  opt_betas: (0.9, 0.98)
  opt_eps: 1e-9
  step: 2
  step2: 20

DATA:
  name: GraphDataset
  valid_batch_size: 128
  candidate_answer_path: KR_VQR/candidate_answers.json
  candidate_answer_e_path: KR_VQR/candidate_answers_e.json
  candidate_answer_r_path: KR_VQR/candidate_answers_r.json
  img_feature_path: /export/home2/NoCsBack/hci/mingxiao/feats/vg_object_cls.lmdb
  path: KR_VQR/clean_{split}.json
  word_count_path: KR_VQR/reason_data_triplet_word_count.json
  kg_path: KR_VQR/all_fact_list.json
  retrieval_kg_path: KR_VQR/retrieval_out.json
  kg_to_lang_path: KR_VQR/knowledge_triplet_language.json
  word2index_path: KR_VQR/word2index.json
  scene_graph_path: KR_VQR/vg_scene_graph.json
  object_path: KR_VQR/rcnn_objects.json
  synset_path: KR_VQR/synsets.json
  ge_scene_graph_info: visual_genome/GeneratedSceneGraph/vg_pred_info.json  
  ge_scene_graph: visual_genome/GeneratedSceneGraph/vg_pred_sg.h5
  max_region: 36
  max_img_node_len: 2 # 10 for using scene graph 2 for using predicted syumbolic
  max_num_img_edge: 180 # 10 for using scene graph 180 for using predicted symbolic
  max_seq_len: 32
  k_nearest: 5
  split: train
  use_split_answer_sets: True
  ori_region_loc: True 
  load_retrieval_kg: True 
  max_kg_ele_len: 10 
  top_k_kg: 10 
  use_scene_graph: False
  use_symbolic: True 
  use_lang_graph: False 
  use_gt_sg: False 
  put_answer_in_graph: False 


